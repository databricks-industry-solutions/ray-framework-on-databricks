{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e7b9607-0347-4d29-b3cc-ecc1574e2073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fetch models from Hugging face hub, tag and store to mlflow UC registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69110445-7b4b-45f7-9f62-651db235005c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade accelerate mlflow-skinny optree>=0.13.0 torch torchvision transformers\n",
    "\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21e08593-6603-4af1-8ec4-c031947184c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client  = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "919e189e-a63d-4cfb-bddb-2edc95428b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = \"amine_elhelou\"\n",
    "SCHEMA = \"ray_gtm_examples\"\n",
    "VOLUME = \"transcribe-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4be9f9a7-0bed-4949-abdd-ef14f8bb2fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ASR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d456ce6b-8801-4ba8-a5b1-e8ba9b07ca7c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build pipeline"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float32 #.float16 for model size reduction\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model_args = {\n",
    "      \"chunk_length_s\" : 30,\n",
    "      \"language\" : \"en\"\n",
    "    }\n",
    "\n",
    "asr_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    model_kwargs=model_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99e402e0-6af1-46ec-93f0-70f8a777742b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Snap model to UC registry [Recommended]"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "ASR_MODEL_NAME = model_id.split(\"/\")[-1]\n",
    "\n",
    "# Log the pipeline\n",
    "with mlflow.start_run(run_name=\"whisper-transcriber-log-pipeline\"):\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=asr_pipe,\n",
    "        artifact_path=\"whisper_transcriber\",\n",
    "        input_example=\"/path/to/audio.file\",\n",
    "        registered_model_name=f\"{CATALOG}.{SCHEMA}.{ASR_MODEL_NAME}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "622691ff-dec5-4002-ad7f-4b72086e19c3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tag model as @Production"
    }
   },
   "outputs": [],
   "source": [
    "client.set_registered_model_alias(\n",
    "  name=f\"{CATALOG}.{SCHEMA}.{ASR_MODEL_NAME}\",\n",
    "  version=model_info.registered_model_version,\n",
    "  alias=\"production\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef881c38-0232-45fd-96f4-038dad13c7a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PII Redaction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdd329d9-0318-424c-8db7-dac1eb4cc855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "PII_MODEL_NAME = model_id.split(\"/\")[-1] # for registered model name\n",
    "pii_pipeline = pipeline(\"ner\", model=model_id, device=\"cuda:0\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"pii-redactor-log-pipeline\"):\n",
    "    pii_model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=pii_pipeline,\n",
    "        artifact_path=\"pii_model\",\n",
    "        input_example=\"Sample text with PII\",\n",
    "        registered_model_name=f\"{CATALOG}.{SCHEMA}.{PII_MODEL_NAME}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d573d931-f70d-4deb-ade0-1998688a7f16",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tag as @Production"
    }
   },
   "outputs": [],
   "source": [
    "client.set_registered_model_alias(\n",
    "  name=f\"{CATALOG}.{SCHEMA}.{PII_MODEL_NAME}\",\n",
    "  version=pii_model_info.registered_model_version,\n",
    "  alias=\"production\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01 Download Models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
